{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the PySpark environment variables\n",
    "import os\n",
    "import sys\n",
    "os.environ['SPARK_HOME'] = r\"C:\\_dev\\spark-3.5.1-hadoop3\"\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "# os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pyspark\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark\n",
    "\n",
    "# importing sparksession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# creating a sparksession object\n",
    "# and providing appName\n",
    "spark = SparkSession.builder.appName(\"pyspark_window\").getOrCreate()\n",
    "\n",
    "# sample data for dataframe\n",
    "sampleData = (\n",
    "    (\"Ram\", 28, \"Sales\", 3000),\n",
    "    (\"Meena\", 33, \"Sales\", 4600),\n",
    "    (\"Robin\", 40, \"Sales\", 4100),\n",
    "    (\"Kunal\", 25, \"Finance\", 3000),\n",
    "    (\"Ram\", 28, \"Sales\", 3000),\n",
    "    (\"Srishti\", 46, \"Management\", 3300),\n",
    "    (\"Jeny\", 26, \"Finance\", 3900),\n",
    "    (\"Hitesh\", 30, \"Marketing\", 3000),\n",
    "    (\"Kailash\", 29, \"Marketing\", 2000),\n",
    "    (\"Sharad\", 39, \"Sales\", 4100),\n",
    ")\n",
    "\n",
    "# column names for dataframe\n",
    "columns = [\"Employee_Name\", \"Age\", \"Department\", \"Salary\"]\n",
    "\n",
    "# creating the dataframe df\n",
    "df = spark.createDataFrame(data=sampleData, schema=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Employee_Name: string (nullable = true)\n",
      " |-- Age: long (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      "\n",
      "+-------------+---+----------+------+\n",
      "|Employee_Name|Age|Department|Salary|\n",
      "+-------------+---+----------+------+\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|        Meena| 33|     Sales|  4600|\n",
      "|        Robin| 40|     Sales|  4100|\n",
      "|        Kunal| 25|   Finance|  3000|\n",
      "|          Ram| 28|     Sales|  3000|\n",
      "|      Srishti| 46|Management|  3300|\n",
      "|         Jeny| 26|   Finance|  3900|\n",
      "|       Hitesh| 30| Marketing|  3000|\n",
      "|      Kailash| 29| Marketing|  2000|\n",
      "|       Sharad| 39|     Sales|  4100|\n",
      "+-------------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating a window\n",
    "# partition of dataframe\n",
    "windowPartition = Window.partitionBy(\"Department\").orderBy(\"Age\")\n",
    " \n",
    "# print schema\n",
    "df.printSchema()\n",
    " \n",
    "# show df\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+---------+\n",
      "|Employee_Name|Age|Department|Salary|cume_dist|\n",
      "+-------------+---+----------+------+---------+\n",
      "|        Kunal| 25|   Finance|  3000|      0.5|\n",
      "|         Jeny| 26|   Finance|  3900|      1.0|\n",
      "|      Srishti| 46|Management|  3300|      1.0|\n",
      "|      Kailash| 29| Marketing|  2000|      0.5|\n",
      "|       Hitesh| 30| Marketing|  3000|      1.0|\n",
      "|          Ram| 28|     Sales|  3000|      0.4|\n",
      "|          Ram| 28|     Sales|  3000|      0.4|\n",
      "|        Meena| 33|     Sales|  4600|      0.6|\n",
      "|       Sharad| 39|     Sales|  4100|      0.8|\n",
      "|        Robin| 40|     Sales|  4100|      1.0|\n",
      "+-------------+---+----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing cume_dist()\n",
    "# from pyspark.sql.functions\n",
    "from pyspark.sql.functions import cume_dist\n",
    "\n",
    "# applying window function with\n",
    "# the help of DataFrame.withColumn cumulative distribution ??????\n",
    "df.withColumn(\"cume_dist\",\n",
    "\t\t\tcume_dist().over(windowPartition)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+----------+------+----+\n",
      "|Employee_Name|Age|Department|Salary| Lag|\n",
      "+-------------+---+----------+------+----+\n",
      "|        Kunal| 25|   Finance|  3000|NULL|\n",
      "|         Jeny| 26|   Finance|  3900|3000|\n",
      "|      Srishti| 46|Management|  3300|NULL|\n",
      "|      Kailash| 29| Marketing|  2000|NULL|\n",
      "|       Hitesh| 30| Marketing|  3000|2000|\n",
      "|          Ram| 28|     Sales|  3000|NULL|\n",
      "|          Ram| 28|     Sales|  3000|3000|\n",
      "|        Meena| 33|     Sales|  4600|3000|\n",
      "|       Sharad| 39|     Sales|  4100|4600|\n",
      "|        Robin| 40|     Sales|  4100|4100|\n",
      "+-------------+---+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing lag() from pyspark.sql.functions\n",
    "from pyspark.sql.functions import lag\n",
    "\n",
    "df.withColumn(\"Lag\", lag(\"Salary\", 1).over(windowPartition)) \\\n",
    "\t.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
